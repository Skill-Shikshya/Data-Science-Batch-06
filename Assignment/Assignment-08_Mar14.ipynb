{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **Assignment: Logistic Regression from Scratch using the Iris Dataset**\n",
    "\n",
    "## **Objective:**\n",
    "Implement Logistic Regression **from scratch** (without using built-in classifiers like those in `sklearn`) to classify flowers in the Iris dataset. Evaluate your model using performance metrics including:\n",
    "\n",
    "- **Confusion Matrix (CM)**\n",
    "- **Precision**\n",
    "- **Recall**\n",
    "- **F1-Score**\n",
    "- **Accuracy**\n",
    "\n",
    "### **Report:**\n",
    "Your final submission should include:\n",
    "\n",
    "- Code (well-commented)\n",
    "- Confusion matrix visualization\n",
    "- Metric values for your trained model\n",
    "- A brief explanation of each step and your results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Instructions:**\n",
    "\n",
    "### 1. **Dataset: Iris Dataset**\n",
    "- Download the Iris dataset from Kaggle: [https://www.kaggle.com/datasets/uciml/iris](https://www.kaggle.com/datasets/uciml/iris)\n",
    "- The dataset contains 150 samples with 4 features:\n",
    "  - Sepal Length\n",
    "  - Sepal Width\n",
    "  - Petal Length\n",
    "  - Petal Width\n",
    "- Target classes:\n",
    "  - Setosa\n",
    "  - Versicolor\n",
    "  - Virginica\n",
    "\n",
    "> **Note**: For binary classification, you may choose any two classes (e.g., Setosa vs Versicolor) or implement a one-vs-rest strategy for multiclass.\n",
    "\n",
    "### 2. **Preprocessing:**\n",
    "- Load and inspect the dataset\n",
    "- Normalize or standardize features as needed\n",
    "- Encode labels (e.g., using 0 and 1 for binary classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. **Model Implementation: Logistic Regression**\n",
    "- Implement logistic regression from scratch (i.e., use NumPy but **no sklearn classifiers**)\n",
    "- Use the sigmoid function for predictions\n",
    "- Apply gradient descent to minimize the loss function (Binary Cross Entropy)\n",
    "- Train the model on the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **Evaluation Metrics:**\n",
    "After training your model, evaluate its performance using the following metrics:\n",
    "\n",
    "- **Confusion Matrix (CM)**: Show a 2x2 table for binary classification.\n",
    "- **Precision**: TP / (TP + FP)\n",
    "- **Recall**: TP / (TP + FN)\n",
    "- **F1-Score**: 2 × (Precision × Recall) / (Precision + Recall)\n",
    "- **Accuracy**: (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "You can implement these metrics manually or use `sklearn.metrics` for validation purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Bonus:**\n",
    "- Extend your model to handle **multiclass classification** (one-vs-rest or softmax-based logistic regression)\n",
    "- Compare your implementation's performance to that of `sklearn.linear_model.LogisticRegression`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
